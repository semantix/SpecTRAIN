{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25cdd0e4-7fc0-4877-aef9-c442d4b2e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install cloudml-hypertune\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85572b12-b384-4316-bf25-a1c7a73691d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = !gcloud storage ls\n",
    "BUCKET = BUCKET[-1].split(\"//\")[-1]\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91a37bd-4993-408d-9c1f-7273a462749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b326f3-a6ff-4286-b8f5-7e18c9088ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [ai/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project ${PROJECT}\n",
    "gcloud config set ai/region ${REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42ffdd-ac1f-4529-abff-358372e46d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an init file to identify the following code as a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb78de0-9bdb-4bd4-a621-bb1185bd7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p spectrain_proc_img/trainer\n",
    "touch spectrain_proc_img/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24c639-3564-4715-8e96-1e19affbc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file to parse the arguments\n",
    "# We will use this later to parse arguments when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2db52a4b-e395-4545-ae25-d0a66437c720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spectrain_proc_img/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spectrain_proc_img/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--train_data_path\",\n",
    "        help=\"GCS location of training data\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_data_path\",\n",
    "        help=\"GCS location of evaluation data\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"GCS location to write checkpoints and export models\",\n",
    "        default = os.getenv(\"AIP_MODEL_DIR\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        help=\"Number of examples to compute gradient over.\",\n",
    "        type=int,\n",
    "        default=64\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nnsize_1\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=256\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nnsize_2\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=128\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ksize\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=4\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pool_ksize\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=2\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--filt_size1\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=64\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--filt_size2\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_epochs\",\n",
    "        help=\"Number of epochs to train the model.\",\n",
    "        type=int,\n",
    "        default=10\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_examples\",\n",
    "        help=\"\"\"Number of examples (in thousands) to run the training job over.\n",
    "        If this is more than actual # of examples available, it cycles through\n",
    "        them. So specifying 1000 here when you have only 100k examples makes\n",
    "        this 10 epochs.\"\"\",\n",
    "        type=int,\n",
    "        default=5000\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_steps\",\n",
    "        help=\"\"\"Positive number of steps for which to evaluate model. Default\n",
    "        to None, which means to evaluate until input_fn raises an end-of-input\n",
    "        exception\"\"\",\n",
    "        type=int,\n",
    "        default=None\n",
    "    )\n",
    "\n",
    "    # Parse all arguments\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "\n",
    "    # Modify some arguments\n",
    "    arguments[\"train_examples\"] *= 100\n",
    "\n",
    "    # Run the training job\n",
    "    model.train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151c441-cf68-44d5-ad5f-ed12cad77248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place all the preprocessing, model building, training and evaluation code in this cell to package in\n",
    "# model.py to later train directly in vertex ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d299d6e6-4f0e-4a5f-abbe-de11a9c51436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spectrain_proc_img/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spectrain_proc_img/trainer/model.py\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hypertune\n",
    "import numpy as np\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import credentials\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (Conv1D, Dense, Dropout, Flatten, MaxPooling1D, Softmax)\n",
    "\n",
    "def get_blob(blobs):\n",
    "    for blob in blobs:\n",
    "        yield blob\n",
    "        \n",
    "def get_image_paths(image_input_dir):\n",
    "    # initialize the GCS client\n",
    "    image_bucket = image_input_dir.split('/')[2]\n",
    "    prefix_dir = '/'.join(image_input_dir.split('/')[3:])\n",
    "    prefix_dir = prefix_dir[1:]\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # get the storage bucket\n",
    "    bucket = storage_client.get_bucket(image_bucket)\n",
    "\n",
    "    image_paths=[]\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(image_bucket, prefix=prefix_dir)\n",
    "    \n",
    "    for blob in get_blob(blobs):\n",
    "        if \"output\" in blob.name:\n",
    "            image_paths.append('gs://spectrain_new/'+blob.name)\n",
    "            \n",
    "    return image_paths\n",
    "\n",
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, convert the data type to\n",
    "    # floating point, and resize it\n",
    "    \n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (256,256))\n",
    "    # parse the class label from the file path\n",
    "    label = tf.strings.split(imagePath, os.path.sep)[-2]\n",
    "    if label=='positive':\n",
    "        label=1\n",
    "    else:\n",
    "        label=0\n",
    "    # return the image and the label\n",
    "    return (image, label)\n",
    "\n",
    "def load_dataset(images_dir, batch_size, training):\n",
    "    \n",
    "    filePaths = get_image_paths(image_input_dir=images_dir)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(filePaths)\n",
    "    ds = (ds.map(load_images).cache().shuffle(len(filePaths)).batch(batch_size))\n",
    "\n",
    "    if training:\n",
    "        return ds.repeat()\n",
    "    else:\n",
    "        return ds\n",
    "\n",
    "def build_model(filter_size_1, filter_size_2, ksize, pool_kernel_size, hidden_units_1, hidden_units_2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filter_size_1, kernel_size=ksize, activation='relu', input_shape=(256, 256)))\n",
    "    model.add(Conv1D(filter_size_1, kernel_size=ksize, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_kernel_size))\n",
    "    model.add(Conv1D(filter_size_2, kernel_size=ksize,activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_kernel_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hidden_units_1, activation='relu'))\n",
    "    model.add(Dense(hidden_units_1, activation='relu'))\n",
    "    model.add(Dense(hidden_units_2, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "# Instantiate the HyperTune reporting object\n",
    "hpt = hypertune.HyperTune()\n",
    "\n",
    "# Reporting callback\n",
    "class HPTCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global hpt\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "            hyperparameter_metric_tag='auc',\n",
    "            metric_value=logs['val_auc'],\n",
    "            global_step=epoch)\n",
    "        \n",
    "        \n",
    "def train_and_evaluate(args):\n",
    "    filt_size_1 = int(args[\"filt_size1\"])\n",
    "    filt_size_2 = int(args[\"filt_size2\"])\n",
    "    ksize = int(args['ksize'])\n",
    "    pool_kernel_size = int(args['pool_ksize'])\n",
    "    hidden_units_1 = int(args['nnsize_1'])\n",
    "    hidden_units_2 = int(args['nnsize_2'])\n",
    "    \n",
    "    model = build_model(filter_size_1=filt_size_1, filter_size_2=filt_size_2, \n",
    "                        ksize=ksize, pool_kernel_size=pool_kernel_size\n",
    "                        , hidden_units_1=hidden_units_1, hidden_units_2=hidden_units_2)\n",
    "\n",
    "    trainds = load_dataset(args[\"train_data_path\"], args[\"batch_size\"], training=True)\n",
    "\n",
    "    evalds = load_dataset(args[\"eval_data_path\"], args[\"batch_size\"], training=False)\n",
    "    \n",
    "    if args[\"eval_steps\"]:\n",
    "        evalds = evalds.take(count=args[\"eval_steps\"])\n",
    "\n",
    "    num_batches = args[\"batch_size\"] * args[\"num_epochs\"]\n",
    "    steps_per_epoch = args[\"train_examples\"] // args[\"batch_size\"]\n",
    "    \n",
    "    checkpoint_path = os.path.join(args[\"output_dir\"], \"checkpoints/spectrain_proc_img\")\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, verbose=1, save_weights_only=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        trainds,\n",
    "        validation_data=evalds,\n",
    "        epochs=args[\"num_epochs\"],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=[cp_callback, HPTCallback()])\n",
    "    \n",
    "    EXPORT_PATH = os.path.join(\n",
    "        args[\"output_dir\"], datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "    tf.saved_model.save(\n",
    "        obj=model, export_dir=EXPORT_PATH)  # with default serving function\n",
    "    \n",
    "    print(\"Exported trained model to {}\".format(EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332c410-bf36-4c99-bf6d-7500e9b73062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The following is the code to train the model on vertex ai with a randomly selected hyperparameters ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88d755e1-54a1-4ca3-b204-94c4b871d5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spectrain_proc_img/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spectrain_proc_img/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='spectrain_proc_img_trainer',\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='spectrain edge detected image model training application.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffa19e-7b01-438e-978b-469792c0a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local directory to store source distribution package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e6ab876-8161-4d0c-a056-d552dd6fae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing spectrain_proc_img_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to spectrain_proc_img_trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to spectrain_proc_img_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'spectrain_proc_img_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'spectrain_proc_img_trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating spectrain_proc_img_trainer-0.1\n",
      "creating spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "creating spectrain_proc_img_trainer-0.1/trainer\n",
      "copying files to spectrain_proc_img_trainer-0.1...\n",
      "copying setup.py -> spectrain_proc_img_trainer-0.1\n",
      "copying spectrain_proc_img_trainer.egg-info/PKG-INFO -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying spectrain_proc_img_trainer.egg-info/SOURCES.txt -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying spectrain_proc_img_trainer.egg-info/dependency_links.txt -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying spectrain_proc_img_trainer.egg-info/top_level.txt -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying trainer/__init__.py -> spectrain_proc_img_trainer-0.1/trainer\n",
      "copying trainer/model.py -> spectrain_proc_img_trainer-0.1/trainer\n",
      "copying trainer/task.py -> spectrain_proc_img_trainer-0.1/trainer\n",
      "Writing spectrain_proc_img_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'spectrain_proc_img_trainer-0.1' (and everything under it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd spectrain_proc_img\n",
    "python ./setup.py sdist --formats=gztar\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "497dc4e9-ce83-45d8-8cf1-9655a77cc90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://spectrain_proc_img/dist/spectrain_proc_img_trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  3.0 KiB/  3.0 KiB]                                                \n",
      "Operation completed over 1 objects/3.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp spectrain_proc_img/dist/spectrain_proc_img_trainer-0.1.tar.gz gs://${BUCKET}/spectrain_cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9d493-a2f3-4ae3-8403-d4f515d8e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit model training to vertex ai with specific random hyperparameters\n",
    "# and passing them as arguments through .yaml file to task.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d547ce00-b347-4eac-82a7-2675cd64a31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/469700469475/locations/us-central1/customJobs/8681114754829254656] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/469700469475/locations/us-central1/customJobs/8681114754829254656\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/469700469475/locations/us-central1/customJobs/8681114754829254656\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/spectrain_cnn/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=spectrain_cnn_hpt_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/spectrain_cnn/spectrain_proc_img_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam2.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: auc\n",
    "    goal: MAXIMIZE\n",
    "  parameters:\n",
    "  - parameterId: batch_size\n",
    "    discreteValueSpec:\n",
    "      values:\n",
    "      - 32\n",
    "      - 64\n",
    "  - parameterId: nnsize_1\n",
    "    discreteValueSpec:\n",
    "      values:\n",
    "      - 256\n",
    "      - 512\n",
    "  - parameterId: nnsize_2\n",
    "    discreteValueSpec:\n",
    "      values:\n",
    "      - 64\n",
    "      - 128\n",
    "  - parameterId: filt_size1\n",
    "    discreteValueSpec:\n",
    "      values:\n",
    "      - 16\n",
    "      - 32\n",
    "      - 64\n",
    "  - parameterId: filt_size2\n",
    "    discreteValueSpec:\n",
    "      values:\n",
    "      - 8\n",
    "      - 16\n",
    "      - 32\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "      acceleratorType: NVIDIA_TESLA_V100\n",
    "      acceleratorCount: 1\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "      - --train_data_path=gs://${BUCKET}/bhavani/train_images\n",
    "      - --eval_data_path=gs://${BUCKET}/bhavani/valid_images\n",
    "      - --num_epochs=20\n",
    "      - --train_examples=5000\n",
    "      - --eval_steps=100\n",
    "      - --batch_size=32\n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam2.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ecc59-4a06-454b-8a1b-54e2ab5a1382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
