{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd356671-2854-4fca-a751-6aa2f3eac98a",
   "metadata": {},
   "source": [
    "## Load needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a94cd2d5-22d3-4cfb-adf6-674cb7e24e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import credentials # NOTE this is for future adaption for MCC deployed solution using creds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219455d1-260c-4821-939f-f06d52845347",
   "metadata": {},
   "source": [
    "### Define the functions to be used for processing and persisting data\n",
    "\n",
    "The get_blobs function is a generator for iterating over the GCS bucket objects\n",
    "\n",
    "The write_png_to_gcs aids with the creation of the PNG files in GCS from the original signals spectra files\n",
    "\n",
    "The write_df_to_gcs is used to create the enriched CSV file from the provided dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af79fbf-a332-4727-bb71-0e831626d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function for iterating over the blobs in a GCS bucket\n",
    "def get_blob(blobs):\n",
    "    for blob in blobs:\n",
    "        yield blob\n",
    "\n",
    "# Function to write the PNG file based on the spectra data plot (300x40) \n",
    "# to a png image file in the provided GCS 'bucket' at the specified 'image_dir' path        \n",
    "def write_png_to_gcs(blob, image_dir, bucket):\n",
    "    print(blob.name)\n",
    "    #NOTE: important to use pyplot instantiation this way to ensure no memory leaks\n",
    "    fig = plt.figure(num=1,figsize=(300,40), clear=True)\n",
    "    data = blob.download_as_bytes()\n",
    "    df = pd.read_csv(io.BytesIO(data), sep='\\s', header=None)\n",
    "    # df=pd.read_csv(blob.name, sep='\\s', header=None)\n",
    "    # filename=filename.split('.')[0]\n",
    "    df.columns=['x_axis', 'y_axis']\n",
    "    ax = fig.add_subplot()\n",
    "    ax.plot(df['x_axis'], df['y_axis'])\n",
    "    ax.axis('off')\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "\n",
    "    filename = blob.name.split('.')[0] # remove the suffix/file extension\n",
    "    filename = filename.split('/')[1] # remove the containing directory name from filename\n",
    "\n",
    "    upload_blob = bucket.blob(image_dir+filename+'_nmr.png')\n",
    "    upload_blob.upload_from_file(buf, content_type='image/png', rewind=True)\n",
    "\n",
    "    # plt.close()\n",
    "    buf.close()\n",
    "    del df\n",
    "    # del plt\n",
    "    del data\n",
    "    del upload_blob\n",
    "    \n",
    "    return\n",
    "\n",
    "# Write DataFrame content to the specified 'file_path' in the given GCS 'bucket'\n",
    "def write_df_to_gcs(df, file_path, bucket):\n",
    "    upload_blob = bucket.blob(file_path)\n",
    "    upload_blob.upload_from_string(df.to_csv(), content_type='text/csv')\n",
    "    \n",
    "    del upload_blob\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e8269-65ba-46a6-a81f-fe360c866546",
   "metadata": {},
   "source": [
    "### Data enrichment functions\n",
    "Define the enrichment functions to calculate eGFR and time.TX values for each row of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c534b67-99c3-458f-8961-99b005a8c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Carried over from Jeff's notebook here for pre-processing and feature engg\n",
    "# Define the CKD-EPI equation function\n",
    "def calculate_eGFR(row):\n",
    "    if row['Sex'] == 'male':\n",
    "        kappa = 0.9\n",
    "        alpha = -0.302\n",
    "        beta = 1.0\n",
    "    else:\n",
    "        kappa = 0.7\n",
    "        alpha = -0.241\n",
    "        beta = 1.012\n",
    "\n",
    "    eGFR = 142 * min(row['serum_creatinine'] / kappa, 1)**alpha * \\\n",
    "           max(row['serum_creatinine'] / kappa, 1)**(-1.2) * \\\n",
    "           0.9938**row['Patient.Age.at.Biopsy'] * beta\n",
    "    return eGFR\n",
    "\n",
    "#Calculate the age difference (in years) between the Biopsy and the transplant\n",
    "def calculate_time(row):\n",
    "    return row['Patient.Age.at.Biopsy'] - row['Patient.Age.at.TX']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13861c-5caf-44e8-861e-cfb744989f7e",
   "metadata": {},
   "source": [
    "### Data processing functions\n",
    "The following functions would be used for:  \n",
    "    1. <b>create_input_layers()</b> : Create a dictionary of Keres input layers for each feature  \n",
    "    2. <b>transform(inputs)</b> : Create a dictionary of transformed input tensors   \n",
    "    3. <b>df_to_dataset(dataframe, shuffle, batch_size) </b> : Create a tf.data dataset from a Pandas dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61125520-1436-4d17-854a-57a8322f9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_layers():\n",
    "    \"\"\"Creates dictionary of input layers for each feature.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of `tf.Keras.layers.Input` layers for each feature.\n",
    "    \"\"\"\n",
    "    inputs = {\n",
    "        colname: tf.keras.layers.Input(\n",
    "            name=colname, shape=(1,), dtype=\"float32\"\n",
    "        )\n",
    "        for colname in NUMERICAL_COLUMNS\n",
    "    }\n",
    "\n",
    "    inputs.update(\n",
    "        {\n",
    "            colname: tf.keras.layers.Input(\n",
    "                name=colname, shape=(1,), dtype=\"string\"\n",
    "            )\n",
    "            for colname in CATEGORICAL_COLUMNS\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def transform(inputs):\n",
    "    \"\"\"Creates dictionary of transformed inputs.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of transformed Tensors\n",
    "    \"\"\"\n",
    "\n",
    "    transformed = {}\n",
    "    for numerical_column in NUMERICAL_COLUMNS:\n",
    "        transformed[numerical_column] = inputs[numerical_column]\n",
    "\n",
    "    vocab = {\n",
    "        \"Sex\": [\"male\", \"female\", \"unknown\"],\n",
    "        \"Diabetes\": [\"True\", \"False\"],\n",
    "        \"Hypertension\": [\"True\", \"False\"],\n",
    "        \"UA.Pro\": [\"True\", \"False\", \"NaN\"],\n",
    "        \"UA.Hb\": [\"True\", \"False\", \"NaN\"],\n",
    "    }\n",
    "\n",
    "    for categorical_column in CATEGORICAL_COLUMNS:\n",
    "        transformed[categorical_column] = tf.keras.layers.StringLookup(\n",
    "            vocabulary=vocab[categorical_column], output_mode=\"one_hot\"\n",
    "        )(inputs[categorical_column])\n",
    "\n",
    "    return transformed\n",
    "\n",
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"median_house_value\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655390b1-eae9-4625-bb36-eb09616dc846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient.ID</th>\n",
       "      <th>Patient.Age.at.Biopsy</th>\n",
       "      <th>Patient.Age.at.TX</th>\n",
       "      <th>Case</th>\n",
       "      <th>Sex</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>hippurate</th>\n",
       "      <th>phenylacetylglutamine</th>\n",
       "      <th>trigonellin</th>\n",
       "      <th>urea</th>\n",
       "      <th>...</th>\n",
       "      <th>citrate</th>\n",
       "      <th>dimethylamine</th>\n",
       "      <th>lactate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>UA.Pro</th>\n",
       "      <th>UA.Hb</th>\n",
       "      <th>Spectrum_file</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>time.TX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bhdLeIiEnep6TPu8qeostZ8o(</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>0.039593</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>3.036788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.232653</td>\n",
       "      <td>8.653069</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>output_NormalizationTool_spectrum_zgpr30-urine...</td>\n",
       "      <td>35.472989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8agYxL3U(2m0pcw^vomp*Yu9x</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>0.113517</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>5.663656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105713</td>\n",
       "      <td>0.316157</td>\n",
       "      <td>6.109724</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>output_NormalizationTool_spectrum_zgpr30-urine...</td>\n",
       "      <td>75.030712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l849CAs#0wR1i(EqkyLtIxwZS</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.122959</td>\n",
       "      <td>0.283221</td>\n",
       "      <td>0.172492</td>\n",
       "      <td>7.417329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231169</td>\n",
       "      <td>0.262318</td>\n",
       "      <td>17.866997</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>output_NormalizationTool_spectrum_zgpr30-urine...</td>\n",
       "      <td>70.097644</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lw*R@N7LoSHUuxTIxTs$PWzfg</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>output_NormalizationTool_spectrum_zgpr30-urine...</td>\n",
       "      <td>80.674794</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4oAgnWhMrp$h@B1*Um*PYowCS</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.018280</td>\n",
       "      <td>0.041485</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>3.556433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010481</td>\n",
       "      <td>0.356004</td>\n",
       "      <td>6.239394</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>output_NormalizationTool_spectrum_zgpr30-urine...</td>\n",
       "      <td>44.147343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Patient.ID  Patient.Age.at.Biopsy  Patient.Age.at.TX  Case  \\\n",
       "0  bhdLeIiEnep6TPu8qeostZ8o(                     55                 55     0   \n",
       "1  8agYxL3U(2m0pcw^vomp*Yu9x                     56                 55     0   \n",
       "2  l849CAs#0wR1i(EqkyLtIxwZS                     58                 58     0   \n",
       "3  lw*R@N7LoSHUuxTIxTs$PWzfg                     47                 45     0   \n",
       "4  4oAgnWhMrp$h@B1*Um*PYowCS                     22                 22     1   \n",
       "\n",
       "      Sex  serum_creatinine  hippurate  phenylacetylglutamine  trigonellin  \\\n",
       "0    male              2.15   0.027913               0.039593     0.012358   \n",
       "1  female              0.90   0.012763               0.113517     0.040703   \n",
       "2    male              1.20   0.122959               0.283221     0.172492   \n",
       "3    male              1.13        NaN                    NaN          NaN   \n",
       "4  female              1.67   0.018280               0.041485     0.010831   \n",
       "\n",
       "       urea  ...   citrate  dimethylamine    lactate  Diabetes Hypertension  \\\n",
       "0  3.036788  ...  0.040761       0.232653   8.653069     False        False   \n",
       "1  5.663656  ...  0.105713       0.316157   6.109724     False         True   \n",
       "2  7.417329  ...  0.231169       0.262318  17.866997     False        False   \n",
       "3       NaN  ...       NaN            NaN        NaN      True         True   \n",
       "4  3.556433  ...  0.010481       0.356004   6.239394     False        False   \n",
       "\n",
       "  UA.Pro  UA.Hb                                      Spectrum_file       eGFR  \\\n",
       "0    NaN    NaN  output_NormalizationTool_spectrum_zgpr30-urine...  35.472989   \n",
       "1  False  False  output_NormalizationTool_spectrum_zgpr30-urine...  75.030712   \n",
       "2  False  False  output_NormalizationTool_spectrum_zgpr30-urine...  70.097644   \n",
       "3    NaN    NaN  output_NormalizationTool_spectrum_zgpr30-urine...  80.674794   \n",
       "4   True  False  output_NormalizationTool_spectrum_zgpr30-urine...  44.147343   \n",
       "\n",
       "   time.TX  \n",
       "0        0  \n",
       "1        1  \n",
       "2        0  \n",
       "3        2  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE: This is commented out as the images (png files) for the spectra are already generated now\n",
    "# image_dir='spec_train_output/images/'\n",
    "\n",
    "# initialize the GCS client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# get the storage bucket\n",
    "bucket = storage_client.get_bucket('spectrain')\n",
    "\n",
    "## NOTE: This is commented out as the images (png files) for the spectra are already generated now\n",
    "# # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "# blobs = storage_client.list_blobs('spectrain', prefix='Kidney_TX_Data')\n",
    "\n",
    "# i = 0 # counter to use for breaking\n",
    "\n",
    "# # Note: The call returns a response only when the iterator is consumed.\n",
    "# for blob in get_blob(blobs):\n",
    "#     if(\"output\" in blob.name):\n",
    "#         write_png_to_gcs(blob, image_dir, bucket)\n",
    "#         # i = i+1\n",
    "#         # if(i == 3):\n",
    "#         #     break;\n",
    "\n",
    "df=pd.read_csv('gs://spectrain/Kidney_TX_Data/Kidney_TX_data.csv')\n",
    "df = df.filter(regex=r'^(?!LS|Banff|Biopsy|Source|Patient.S|Nmr)')\n",
    "\n",
    "# Apply the calculate_eGFR function to create the 'eGFR' column\n",
    "df['eGFR'] = df.apply(calculate_eGFR, axis=1)\n",
    "# Apply the calculate_time function to create the 'time.TX' column\n",
    "df['time.TX'] = df.apply(calculate_time, axis=1)\n",
    "\n",
    "write_df_to_gcs(df, 'Kidney_TX_enriched_data.csv', bucket)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24248d0-0fb3-447a-aec1-e3df1afdfd6c",
   "metadata": {},
   "source": [
    "### Define a Simple LogisticRegression model for our tabular features and label (Case)\n",
    "\n",
    "We will use the dataframe 'df' formed above to form a simple LogisticRegression model and make some\n",
    "predictions and evaluate against the testing data and report that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "891aa46c-c4ad-410a-bb2d-ab1b9e80365e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('simple',\n",
       "                                                  SimpleImputer(strategy='median'),\n",
       "                                                  ['serum_creatinine',\n",
       "                                                   'hippurate',\n",
       "                                                   'phenylacetylglutamine',\n",
       "                                                   'trigonellin', 'urea',\n",
       "                                                   'citrate', 'dimethylamine',\n",
       "                                                   'lactate', 'eGFR',\n",
       "                                                   'time.TX']),\n",
       "                                                 ('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['Sex', 'Diabetes',\n",
       "                                                   'Hypertension', 'UA.Pro',\n",
       "                                                   'UA.Hb']),\n",
       "                                                 ('scale', StandardScaler(),\n",
       "                                                  ['serum_creatinine',\n",
       "                                                   'hippurate',\n",
       "                                                   'phenylacetylglutamine',\n",
       "                                                   'trigonellin', 'urea',\n",
       "                                                   'citrate', 'dimethylamine',\n",
       "                                                   'lactate', 'eGFR',\n",
       "                                                   'time.TX'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=10000, random_state=42))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('gs://spectrain/Kidney_TX_enriched_data.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "X = df[[\"serum_creatinine\",\"Sex\",\"hippurate\",\"phenylacetylglutamine\",\n",
    "        \"trigonellin\",\"urea\",\"citrate\",\"dimethylamine\",\"lactate\",\n",
    "        \"Diabetes\",\"Hypertension\",\"UA.Pro\",\"UA.Hb\",\"eGFR\",\"time.TX\"]]\n",
    "y = df[\"Case\"]\n",
    "\n",
    "\n",
    "NUMERICAL_COLUMNS = [\"serum_creatinine\", \"hippurate\", \"phenylacetylglutamine\", \"trigonellin\",\n",
    "                    \"urea\", \"citrate\", \"dimethylamine\", \"lactate\", \"eGFR\", \"time.TX\"]\n",
    "CATEGORICAL_COLUMNS = [\"Sex\", \"Diabetes\", \"Hypertension\", \"UA.Pro\", \"UA.Hb\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)\n",
    "\n",
    "# get the categorical and numeric column names\n",
    "num_cols = X_train.select_dtypes(exclude=['object']).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# pipeline for numerical columns\n",
    "num_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "# # pipeline for categorical columns\n",
    "# cat_pipe = make_pipeline(\n",
    "#     SimpleImputer(strategy='constant', fill_value='N/A'),\n",
    "#     OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "# )\n",
    "\n",
    "# combine both the pipelines\n",
    "# full_pipe = ColumnTransformer([\n",
    "#     ('num', num_pipe, num_cols),\n",
    "#     ('cat', cat_pipe, cat_cols)\n",
    "# ])\n",
    "\n",
    "# # Create input layer\n",
    "# inputs = create_input_layers()\n",
    "\n",
    "# # transform\n",
    "# transformed = transform(inputs)\n",
    "\n",
    "logreg = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"simple\", SimpleImputer(strategy='median'), NUMERICAL_COLUMNS),\n",
    "            (\"ohe\", OneHotEncoder(sparse=False), CATEGORICAL_COLUMNS),\n",
    "            (\"scale\", StandardScaler(with_mean=True), NUMERICAL_COLUMNS),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    ),\n",
    "    LogisticRegression(max_iter=10000, random_state=42),\n",
    ")\n",
    "\n",
    "# train the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae34d0-7da0-4b1e-ae17-4aad627605d7",
   "metadata": {},
   "source": [
    "Now predict the outcomes for the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c99e0569-841c-4d22-ad4b-3bf7e1806122",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a5c271-dcc4-4f11-985b-f2cc3338b483",
   "metadata": {},
   "source": [
    "Finally, show the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e334225c-0924-4e70-87a6-01bb4e24f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83       197\n",
      "           1       0.67      0.17      0.27        84\n",
      "\n",
      "    accuracy                           0.73       281\n",
      "   macro avg       0.70      0.57      0.55       281\n",
      "weighted avg       0.71      0.73      0.66       281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f1526-cfe2-4472-bf66-e69bd32074a4",
   "metadata": {},
   "source": [
    "### Trying a Keras based deep learning model with a neural network of 3 layers\n",
    "\n",
    "First dense layer of 16, second dense layer of 8 and the last layer using sigmoid activation. \n",
    "The first 2 dense layers would use ReLU as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fa8e2-9d1b-4351-86e2-8c5db83ac38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: input_shape is 20 instead of 15 due to the new columns that will be\n",
    "# introduced by the OneHotEncoder column transformers for the 5 categorical columns\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(20,)),\n",
    "    tf.keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "\ttf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['AUC'])\n",
    "\n",
    "# NOTE: cannot use the following construct as unable to use .fit with support for epochs and batch_size params\n",
    "# dnn = make_pipeline(\n",
    "#     ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             (\"simple\", SimpleImputer(strategy='median'), NUMERICAL_COLUMNS),\n",
    "#             (\"ohe\", OneHotEncoder(sparse=False), CATEGORICAL_COLUMNS),\n",
    "#             (\"scale\", StandardScaler(with_mean=True), NUMERICAL_COLUMNS),\n",
    "#         ],\n",
    "#         remainder=\"passthrough\",\n",
    "#     ),\n",
    "#     model,\n",
    "# )\n",
    "\n",
    "# [print(i.shape, i.dtype) for i in model.inputs]\n",
    "# [print(o.shape, o.dtype) for o in model.outputs]\n",
    "# [print(l.name, l.input_shape, l.dtype) for l in model.layers]\n",
    "print(type(X_train))\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"simple\", SimpleImputer(strategy='median'), NUMERICAL_COLUMNS),\n",
    "            (\"ohe\", OneHotEncoder(sparse=False), CATEGORICAL_COLUMNS),\n",
    "            (\"scale\", StandardScaler(with_mean=True), NUMERICAL_COLUMNS),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# train_data = dataset.shuffle(len(X_train)).batch(32)\n",
    "# train_data = train_data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    " \n",
    "# valid_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "# model.fit(train_data, epochs=200, batch_size=4, validation_data=valid_ds)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=4)\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Loss: {test_loss} and test accuracy: {test_acc}\")\n",
    "\n",
    "# NOTE: For printing loss and AUC\n",
    "# test_loss, test_auc = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Loss: {test_loss} and test AUC: {test_auc}\")\n",
    "\n",
    "# Sample output with 1000 epochs and 32 batch size (0.91 for the loss is less than ideal :( )\n",
    "# Test Loss: 0.9106149673461914 and test accuracy: 0.7298578023910522\n",
    "\n",
    "#TODO perhaps try loss, mse instead of loss, accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19110a76-72c1-4112-a039-a8872bd46891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
