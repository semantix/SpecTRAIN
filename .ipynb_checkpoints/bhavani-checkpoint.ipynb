{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7764bb9-fadd-4197-94b2-6330266aff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15e322-32a7-4d0e-8ccd-42c5e8e9606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gcsfs\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import credentials\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961a15c-aeca-4392-a52e-95d54dcb3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob(blobs):\n",
    "    for blob in blobs:\n",
    "        yield blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dca08-168c-4ef9-bc55-200ef359f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(input_dir, image_dir, transform):\n",
    "\n",
    "    # initialize the GCS client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # get the storage bucket\n",
    "    bucket = storage_client.get_bucket('spectrain')\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs('spectrain', prefix=input_dir)\n",
    "    \n",
    "    # Note: The call returns a response only when the iterator is consumed.\n",
    "    for blob in get_blob(blobs):\n",
    "        if(\"output\" in blob.name):\n",
    "            if transform:\n",
    "                \n",
    "                plt.figure(figsize=(200,40), clear=True)\n",
    "                data = blob.download_as_bytes()\n",
    "                img = Image.open(io.BytesIO(data)) \n",
    "                img=np.array(img)\n",
    "                edges = cv.Canny(img,100,200)\n",
    "                plt.axis('off')\n",
    "                buf = io.BytesIO()\n",
    "                edges = Image.fromarray(edges)\n",
    "                edges.save(buf, \"png\")\n",
    "                filename = blob.name.split('.')[0] # remove the suffix/file extension\n",
    "                filename = filename.split('/')[-1] # remove the containing directory name from filename\n",
    "                upload_blob = bucket.blob(image_dir+filename+'.png')\n",
    "                upload_blob.upload_from_file(buf, content_type='image/png', rewind=True)\n",
    "                buf.close()\n",
    "                plt.close(\"all\")\n",
    "                plt.close()\n",
    "                \n",
    "            else:\n",
    "                plt.figure(figsize=(300,40), clear=True)\n",
    "                df=pd.read_csv(\"gs://spectrain/\"+blob.name, sep='\\s', header=None)\n",
    "                df.columns=['x_axis', 'y_axis']\n",
    "                plt.plot(df['x_axis'], df['y_axis'])\n",
    "                plt.axis('off')\n",
    "                buf = io.BytesIO()\n",
    "                filename = blob.name.split('.')[0] # remove the suffix/file extension\n",
    "                filename = filename.split('/')[-1] # remove the containing directory name from filename\n",
    "                plt.savefig(buf, format=\"png\")\n",
    "                upload_blob = bucket.blob(image_dir+filename+'.png')\n",
    "                upload_blob.upload_from_file(buf, content_type='image/png', rewind=True)\n",
    "                buf.close()\n",
    "                plt.close(\"all\")\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad8584-ecad-485c-8138-6d888d6fddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir='spec_train_output/processed_images'\n",
    "output_image_dir='bhavani/transformed_images/'\n",
    "transform=True\n",
    "generate_images(input_dir, output_image_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f122d74-5ffb-4417-913d-6431aad5abe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0a152-2654-4bc9-9337-ae414f200574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create import file for AutoML IMAGE CLASSIFICATION\n",
    "\n",
    "df=pd.read_csv('gs://qwiklabs-asl-00-c812c3b423f2/spec_train_output/input/Kidney_TX_data.csv')\n",
    "df['Spectrum_file_new'] = df.Spectrum_file.str.split('\\.').str[0]\n",
    "df['Spectrum_file_new'] = \"gs://spectrain/spec_train_output/images/\" + df['Spectrum_file_new'] + '_nmr.png'\n",
    "df = df[['Spectrum_file_new', 'Case']]\n",
    "df.to_csv('gs://spectrain/spec_train_output/image_dir_paths_labels1.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689e4a1-c46c-4c77-9564-a47682d5d583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9cf89-e6e2-4046-a6bc-4902d622a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data split column for structured data\n",
    "\n",
    "df=pd.read_csv('gs://qwiklabs-asl-00-c812c3b423f2/spec_train_output/input/Kidney_TX_data.csv')\n",
    "X=df.drop(columns=['Case'])\n",
    "y=df[['Case']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, stratify=y_train, random_state=42)\n",
    "X_train['data_split'] = 'TRAIN'\n",
    "X_val['data_split'] = 'VALID'\n",
    "X_test['data_split'] = 'TEST'\n",
    "X_train['Case'] = y_train\n",
    "X_val['Case'] = y_val\n",
    "X_test['Case'] = y_test\n",
    "final_df=pd.concat([X_train, X_val, X_test])\n",
    "final_df.to_csv('gs://spectrain/Kidney_TX_data_with_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cc6f1-c832-4636-a25c-ea9f8e301a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10971788-d00a-40a7-b3a3-050e0e2ad6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data split column for images data import file\n",
    "data_split_df=pd.read_csv('gs://spectrain/Kidney_TX_data_with_split.csv')\n",
    "image_paths_df=pd.read_csv('gs://spectrain/spec_train_output/image_dir_paths_labels1.csv', header=None)\n",
    "data_split_df['Spectrum_file_new'] = data_split_df.Spectrum_file.str.split('\\.').str[0]\n",
    "data_split_df['Spectrum_file_new'] = \"gs://spectrain/spec_train_output/images/\" + data_split_df['Spectrum_file_new'] + '_nmr.png'\n",
    "data_split_df = data_split_df[['Spectrum_file_new', 'data_split']]\n",
    "image_paths_df.columns=['Spectrum_file_new', 'Case']\n",
    "image_paths_df=pd.merge(image_paths_df, data_split_df, on=['Spectrum_file_new'], how='inner')\n",
    "image_paths_df=image_paths_df[['data_split', 'Spectrum_file_new', 'Case']]\n",
    "image_paths_df['data_split'] = image_paths_df.data_split.replace({'TRAIN':'TRAINING', 'VALID':'VALIDATION', 'TEST':'TEST'})\n",
    "image_paths_df.to_csv('gs://spectrain/spec_train_output/image_dir_paths_labels_with_split.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21399ffc-d52e-4821-860b-b6c2a749d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcd2305-e989-49a4-88d1-c91afdd7761e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141b72a-8836-4265-9602-4120ac253856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e9b10-a8ac-4dbc-b54c-f4e8124f0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression.fit(X_train, y_train)\n",
    "pred_probas=model.predict_proba(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41607707-cac4-4ec5-ae05-10d916a42212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(df, split_name):\n",
    "    pos_files=df[df.label==1].proc_img_dir.values.tolist()\n",
    "    neg_files=df[df.label==0].proc_img_dir.values.tolist()\n",
    "    for (label, class_dir) in [('positive', pos_files), ('negative', neg_files)]:\n",
    "        print(split_name, label)\n",
    "        for files in class_dir:\n",
    "            filename = files.split('/')[-1] # remove the containing directory name from filename\n",
    "            !gsutil cp {files} gs://spectrain/bhavani/{split_name}_images/{label}/{filename}\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d5eee-f192-4ab2-ba98-4658eb7e31e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddaedd7-5a5a-4e6a-a932-a050b3989945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_dir(image_file_path):\n",
    "    df = pd.read_csv(image_file_path, header=None)\n",
    "    df.columns=['split', 'directory', 'label']\n",
    "    df[\"proc_img_dir\"] = \"gs://spectrain/bhavani/transformed_images/\"+df.directory.str.split('/').str[-1]\n",
    "    train_df = df[df.split=='TRAINING']\n",
    "    valid_df = df[df.split=='VALIDATION']\n",
    "    test_df = df[df.split=='TEST']\n",
    "    copy_images(train_df, 'train')\n",
    "    #copy_images(valid_df, 'valid')\n",
    "    #copy_images(test_df, 'test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ae992-cff1-4d34-96af-3a01331792e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = 'gs://spectrain/spec_train_output/image_dir_paths_labels_with_split.csv'\n",
    "#create_train_test_dir(image_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea620cb-d724-4e2f-bda1-29d13f3da61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=image_dataset_from_directory(images_dir, batch_size, image_size=(1600, 25600), shuffle=True, seed=1)\n",
    "ds.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8382ade-a327-4c4b-bf92-ec0227d60460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db5c16-4e56-4641-ac62-21fb59a9cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    " #### START THE CNN MODEL ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96619d02-1cee-4b1a-a059-74e767ad975f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17ad9a-7471-4762-bc07-a4871169013f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eeeb25f-0b70-4f5a-a31a-6992f72a4db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2a01d118-1e18-42f5-a380-a78a210a0ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is blobs <google.api_core.page_iterator.HTTPIterator object at 0x7f0bc0099fd0>\n"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client()\n",
    "\n",
    "# get the storage bucket\n",
    "bucket = storage_client.get_bucket('spectrain')\n",
    "#this is blobs <google.api_core.page_iterator.HTTPIterator object at 0x7f05b2b50a10>\n",
    "image_paths=[]\n",
    "# Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "blobs = storage_client.list_blobs('spectrain', prefix='/bhavani/train_images')\n",
    "print('this is blobs', blobs)\n",
    "for blob in get_blob(blobs):\n",
    "    if \"output\" in blob.name:\n",
    "        print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a409a7eb-f9cb-4b98-8a5a-afcd0012810d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be31d1-0639-4a96-893d-2881e952f4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43739957-5a02-4bfc-93e7-f2703ccef6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [ai/region].\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846d664-db97-4c38-9971-e63ab6c0b5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab2d36-d564-472a-b87c-34c1ef5fa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_image_paths(split_name=\"train\"):\n",
    "    # initialize the GCS client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # get the storage bucket\n",
    "    bucket = storage_client.get_bucket('spectrain')\n",
    "\n",
    "    image_paths=[]\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs('spectrain', prefix=\"bhavani/train_images/\")\n",
    "    \n",
    "    for blob in get_blob(blobs):\n",
    "        if \"output\" in blob.name:\n",
    "            print(blob.name)\n",
    "            #image_paths.append('gs://spectrain/'+blob.name)\n",
    "            \n",
    "    return image_paths\n",
    "'''\n",
    "def load_images(imagePath, split_name=\"train\"):\n",
    "    # read the image from disk, decode it, convert the data type to\n",
    "    # floating point, and resize it\n",
    "    \n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (256,256))\n",
    "    # parse the class label from the file path\n",
    "    label = tf.strings.split(imagePath, os.path.sep)[-2]\n",
    "\n",
    "    # return the image and the label\n",
    "    return (image, label)\n",
    "\n",
    "trainPaths = get_image_paths(split_name)\n",
    "\n",
    "trainDS = tf.data.Dataset.from_tensor_slices(trainPaths)\n",
    "trainDS = (trainDS\n",
    "    .shuffle(len(trainPaths))\n",
    "    .map(load_images)\n",
    "    .cache()\n",
    "    .batch(64)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c9288-55c4-4c68-b04d-ff9fcd8239ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1700d53-d017-47fe-a791-1850ae96fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath=\"gs://spectrain/bhavani/test_images/positive/output_NormalizationTool_spectrum_zgpr30-urine-600MHz-310K_12_575_00000_withoutBackground_20001_nmr.png\"\n",
    "image = tf.io.read_file(imagePath)\n",
    "image = tf.image.decode_png(image, channels=1)\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.image.resize(image, (256,256))\n",
    "# parse the class label from the file path\n",
    "print(tf.strings.split(imagePath, os.path.sep))\n",
    "label = tf.strings.split(imagePath, os.path.sep)[-2]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f60b7e4-2f1f-411e-9ab5-b35326a4b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Custom CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bc0b1b0-dfed-4211-9498-2ba296bd7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f493b14b-d502-4b31-8c98-74ce63ac026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = !gcloud storage ls\n",
    "BUCKET = BUCKET[-1].split(\"//\")[-1]\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "134aeb65-823b-42e8-ba17-5d7af201f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "476367cb-1698-4578-913c-6a6417b569f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [ai/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project ${PROJECT}\n",
    "gcloud config set ai/region ${REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0472f57d-4f14-4877-8ff2-eba5312f1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an init file to identify the following code as a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12c43df6-b578-4a16-a907-c74f7dc9f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p spectrain_proc_img/trainer\n",
    "touch spectrain_proc_img/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f00bcd6f-7185-49eb-8c67-0e240d53eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file to parse the arguments\n",
    "# We will use this later to parse arguments when training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16730f67-39e5-4294-aac0-1636436ea94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spectrain_proc_img/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spectrain_proc_img/trainer/task.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--train_data_path\",\n",
    "        help=\"GCS location of training data\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_data_path\",\n",
    "        help=\"GCS location of evaluation data\",\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"GCS location to write checkpoints and export models\",\n",
    "        default = os.getenv(\"AIP_MODEL_DIR\")\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        help=\"Number of examples to compute gradient over.\",\n",
    "        type=int,\n",
    "        default=64\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nnsize_1\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=512\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nnsize_2\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=64\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ksize\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=4\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--pool_ksize\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=2\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--filt_size1\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=64\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--filt_size2\",\n",
    "        help=\"Hidden layer sizes for DNN -- provide space-separated layers\",\n",
    "        default=32\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_epochs\",\n",
    "        help=\"Number of epochs to train the model.\",\n",
    "        type=int,\n",
    "        default=10\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--train_examples\",\n",
    "        help=\"\"\"Number of examples (in thousands) to run the training job over.\n",
    "        If this is more than actual # of examples available, it cycles through\n",
    "        them. So specifying 1000 here when you have only 100k examples makes\n",
    "        this 10 epochs.\"\"\",\n",
    "        type=int,\n",
    "        default=5000\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--eval_steps\",\n",
    "        help=\"\"\"Positive number of steps for which to evaluate model. Default\n",
    "        to None, which means to evaluate until input_fn raises an end-of-input\n",
    "        exception\"\"\",\n",
    "        type=int,\n",
    "        default=None\n",
    "    )\n",
    "\n",
    "    # Parse all arguments\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "\n",
    "    # Modify some arguments\n",
    "    arguments[\"train_examples\"] *= 100\n",
    "\n",
    "    # Run the training job\n",
    "    model.train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f32a43a3-001c-4546-a877-3e9ef0a9ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place all the preprocessing, model building, training and evaluation code in this cell to package in\n",
    "# model.py to later train directly in vertex ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "791ad21c-a724-4728-bf4a-57d778f5c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spectrain_proc_img/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spectrain_proc_img/trainer/model.py\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import hypertune\n",
    "import numpy as np\n",
    "from google.cloud import bigquery, storage\n",
    "from google.oauth2 import credentials\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import (Conv1D, Dense, Dropout, Flatten, MaxPooling1D, Softmax)\n",
    "\n",
    "def get_blob(blobs):\n",
    "    for blob in blobs:\n",
    "        yield blob\n",
    "        \n",
    "def get_image_paths(image_input_dir):\n",
    "    # initialize the GCS client\n",
    "    image_bucket = image_input_dir.split('/')[2]\n",
    "    prefix_dir = '/'.join(image_input_dir.split('/')[3:])\n",
    "    prefix_dir = prefix_dir[1:]\n",
    "    storage_client = storage.Client()\n",
    "    # get the storage bucket\n",
    "    bucket = storage_client.get_bucket(image_bucket)\n",
    "\n",
    "    image_paths=[]\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(image_bucket, prefix=prefix_dir)\n",
    "    \n",
    "    for blob in get_blob(blobs):\n",
    "        if \"output\" in blob.name:\n",
    "            image_paths.append('gs://spectrain/'+blob.name)\n",
    "    return image_paths\n",
    "\n",
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, convert the data type to\n",
    "    # floating point, and resize it\n",
    "    \n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (256,256))\n",
    "    # parse the class label from the file path\n",
    "    label = tf.strings.split(imagePath, os.path.sep)[-2]\n",
    "    if label=='positive':\n",
    "        label=1\n",
    "    else:\n",
    "        label=0\n",
    "    # return the image and the label\n",
    "    return (image, label)\n",
    "\n",
    "    # return the image and the label\n",
    "    return (image, label)\n",
    "\n",
    "def load_dataset(images_dir, batch_size, training):\n",
    "    \n",
    "    filePaths = get_image_paths(image_input_dir=images_dir)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(filePaths)\n",
    "    ds = (ds\n",
    "        .map(load_images)\n",
    "        .cache()\n",
    "        .shuffle(len(filePaths))\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "\n",
    "    if training:\n",
    "        return ds.repeat()\n",
    "    else:\n",
    "        return ds\n",
    "\n",
    "def build_model(filter_size_1, filter_size_2, kernel_size, pool_kernel_size, hidden_units_1, hidden_units_2):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filter_size_1, kernel_size=kernel_size, activation='relu', input_shape=(256, 256)))\n",
    "    model.add(Conv1D(filter_size_1, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_kernel_size))\n",
    "    model.add(Conv1D(filter_size_2, kernel_size=kernel_size,activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_kernel_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hidden_units_1, activation='relu'))\n",
    "    model.add(Dense(hidden_units_1, activation='relu'))\n",
    "    model.add(Dense(hidden_units_2, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "# Instantiate the HyperTune reporting object\n",
    "hpt = hypertune.HyperTune()\n",
    "\n",
    "# Reporting callback\n",
    "class HPTCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global hpt\n",
    "        hpt.report_hyperparameter_tuning_metric(\n",
    "            hyperparameter_metric_tag='auc',\n",
    "            metric_value=logs['val_auc'],\n",
    "            global_step=epoch)\n",
    "        \n",
    "        \n",
    "def train_and_evaluate(args):\n",
    "    model = build_model(filter_size_1=args[\"filt_size1\"], filter_size_2=args[\"filt_size2\"], \n",
    "                        kernel_size=args['ksize'], pool_kernel_size=args['pool_ksize']\n",
    "                        , hidden_units_1=args['nnsize_1'], hidden_units_2=args['nnsize_2'])\n",
    "\n",
    "    trainds = load_dataset(args[\"train_data_path\"], args[\"batch_size\"], training=True)\n",
    "\n",
    "    evalds = load_dataset(args[\"eval_data_path\"], args[\"batch_size\"], training=False)\n",
    "    \n",
    "    if args[\"eval_steps\"]:\n",
    "        evalds = evalds.take(count=args[\"eval_steps\"])\n",
    "\n",
    "    num_batches = args[\"batch_size\"] * args[\"num_epochs\"]\n",
    "    steps_per_epoch = args[\"train_examples\"] // args[\"batch_size\"]\n",
    "    checkpoint_path = os.path.join(args[\"output_dir\"], \"checkpoints/spectrain_proc_img\")\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, verbose=1, save_weights_only=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        trainds,\n",
    "        validation_data=evalds,\n",
    "        epochs=args[\"batch_size\"],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=[cp_callback, HPTCallback()])\n",
    "    \n",
    "    EXPORT_PATH = os.path.join(\n",
    "        args[\"output_dir\"], datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "    tf.saved_model.save(\n",
    "        obj=model, export_dir=EXPORT_PATH)  # with default serving function\n",
    "    \n",
    "    print(\"Exported trained model to {}\".format(EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e08d54a3-dd48-469d-9188-35d204d91f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train the model locally to check if everything is good #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "240c1ca6-862a-4949-b628-c09b1d8d3c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 129s - loss: 0.6852 - auc: 0.4377 - val_loss: 0.6479 - val_auc: 0.2857 - 129s/epoch - 13s/step\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.6046 - auc: 0.5490 - val_loss: 0.6386 - val_auc: 0.4286 - 466ms/epoch - 47ms/step\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.6643 - auc: 0.5830 - val_loss: 0.6530 - val_auc: 0.7292 - 413ms/epoch - 41ms/step\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.6412 - auc: 0.5767 - val_loss: 0.6194 - val_auc: 0.0938 - 348ms/epoch - 35ms/step\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.6297 - auc: 0.6029 - val_loss: 0.5142 - val_auc: 0.8750 - 423ms/epoch - 42ms/step\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.5816 - auc: 0.5195 - val_loss: 0.9608 - val_auc: 0.4167 - 371ms/epoch - 37ms/step\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.6280 - auc: 0.5914 - val_loss: 0.6487 - val_auc: 0.6458 - 362ms/epoch - 36ms/step\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.5390 - auc: 0.6378 - val_loss: 0.4328 - val_auc: 0.7812 - 362ms/epoch - 36ms/step\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.5949 - auc: 0.4712 - val_loss: 0.3575 - val_auc: 0.8889 - 410ms/epoch - 41ms/step\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: saving model to spectrain_proc_img_trained/checkpoints/spectrain_proc_img\n",
      "10/10 - 0s - loss: 0.6152 - auc: 0.5415 - val_loss: 0.5849 - val_auc: 0.7143 - 359ms/epoch - 36ms/step\n",
      "Exported trained model to spectrain_proc_img_trained/20230614070813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 07:06:00.147020: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-06-14 07:06:00.147078: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-14 07:06:00.147103: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (asl): /proc/driver/nvidia/version does not exist\n",
      "2023-06-14 07:06:00.147413: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 07:06:11.909941: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 92 of 1064\n",
      "2023-06-14 07:06:21.866955: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 193 of 1064\n",
      "2023-06-14 07:06:31.795711: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 293 of 1064\n",
      "2023-06-14 07:06:41.801242: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 395 of 1064\n",
      "2023-06-14 07:06:51.868548: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 497 of 1064\n",
      "2023-06-14 07:07:01.866646: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 593 of 1064\n",
      "2023-06-14 07:07:11.836633: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 685 of 1064\n",
      "2023-06-14 07:07:21.849409: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 788 of 1064\n",
      "2023-06-14 07:07:31.861458: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 889 of 1064\n",
      "2023-06-14 07:07:41.832607: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 990 of 1064\n",
      "2023-06-14 07:07:49.067247: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-06-14 07:07:59.764278: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 98 of 188\n",
      "2023-06-14 07:08:09.860273: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 186 of 188\n",
      "2023-06-14 07:08:10.042049: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2023-06-14 07:08:14.302436: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=spectrain_proc_img_trained\n",
    "rm -rf ${OUTDIR}\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/spectrain_proc_img\n",
    "python3 -m trainer.task \\\n",
    "    --train_data_path=gs://${BUCKET}/bhavani/train_images \\\n",
    "    --eval_data_path=gs://${BUCKET}/bhavani/valid_images \\\n",
    "    --output_dir=${OUTDIR} \\\n",
    "    --batch_size=10 \\\n",
    "    --num_epochs=1 \\\n",
    "    --train_examples=1 \\\n",
    "    --eval_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81a35d-f3cb-46a8-950a-9f62d84b77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The following is the code to train the model on vertex ai with a randomly selected hyperparameters ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee63c6-54d4-4127-864c-869ea77f7eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f31935dc-ef14-4051-a930-3fde233a193e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spectrain_proc_img/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spectrain_proc_img/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='spectrain_proc_img_trainer',\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='spectrain edge detected image model training application.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c59d56b9-7f93-4556-a0e1-01c28d954f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local directory to store source distribution package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "044f8ac9-fc83-48da-8c6f-08dfe6f11ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing spectrain_proc_img_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to spectrain_proc_img_trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to spectrain_proc_img_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'spectrain_proc_img_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'spectrain_proc_img_trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating spectrain_proc_img_trainer-0.1\n",
      "creating spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "creating spectrain_proc_img_trainer-0.1/trainer\n",
      "copying files to spectrain_proc_img_trainer-0.1...\n",
      "copying setup.py -> spectrain_proc_img_trainer-0.1\n",
      "copying spectrain_proc_img_trainer.egg-info/PKG-INFO -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying spectrain_proc_img_trainer.egg-info/SOURCES.txt -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying spectrain_proc_img_trainer.egg-info/dependency_links.txt -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying spectrain_proc_img_trainer.egg-info/top_level.txt -> spectrain_proc_img_trainer-0.1/spectrain_proc_img_trainer.egg-info\n",
      "copying trainer/__init__.py -> spectrain_proc_img_trainer-0.1/trainer\n",
      "copying trainer/model.py -> spectrain_proc_img_trainer-0.1/trainer\n",
      "copying trainer/task.py -> spectrain_proc_img_trainer-0.1/trainer\n",
      "Writing spectrain_proc_img_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'spectrain_proc_img_trainer-0.1' (and everything under it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd spectrain_proc_img\n",
    "python ./setup.py sdist --formats=gztar\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed338cad-4a57-4fe4-80c2-3f5a840f075a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c250af97-32f0-4416-82db-8391f82fa088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://spectrain_proc_img/dist/spectrain_proc_img_trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  3.0 KiB/  3.0 KiB]                                                \n",
      "Operation completed over 1 objects/3.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp spectrain_proc_img/dist/spectrain_proc_img_trainer-0.1.tar.gz gs://${BUCKET}/spectrain_cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb19fce-1af0-4335-b48d-91cb6f7cb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit model training to vertex ai with specific random hyperparameters\n",
    "# and passing them as arguments through .yaml file to task.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f163dd20-520a-4486-a707-e0b5934481a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/469700469475/locations/us-central1/customJobs/6257327133304029184] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/469700469475/locations/us-central1/customJobs/6257327133304029184\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/469700469475/locations/us-central1/customJobs/6257327133304029184\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "OUTDIR=gs://${BUCKET}/spectrain_cnn/trained_model_$TIMESTAMP\n",
    "JOB_NAME=spectrain_cnn_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/spectrain_cnn/spectrain_proc_img_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-standard-4\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/bhavani/train_images\n",
    "    - --eval_data_path=gs://${BUCKET}/bhavani/valid_images\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=10\n",
    "    - --train_examples=10000\n",
    "    - --eval_steps=100\n",
    "    - --batch_size=32\"\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e79bd6-79a3-4c4d-b3fd-5a8bbd71237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The training of model in vertex ai code ends here #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3da40-d889-4951-9e65-3145dc227382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d4cf-d9f5-449a-8774-fe2a54e10ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### The following is the code for hyper parameter tuning ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7925ce-1117-45c6-84f1-f7e6bed0bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfomr hyper parameter tuning using arguments in .YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e039425-3edd-4d6c-ad24-9b7046b494bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2681e-583d-4974-b2f6-d815ec9ee525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "52c15133-bfbe-4c8b-ac1a-3203e0a1708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "ERROR: (gcloud.ai.hp-tuning-jobs.create) FAILED_PRECONDITION: The Cloud Storage bucket of `gs://spectrain//spectrain_cnn/hp_tuning_20230614_073544` is in location `us`. It must be in the same regional location as the service location `us-central1`.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\\nBASE_OUTPUT_DIR=gs://${BUCKET}/spectrain_cnn/hp_tuning_$TIMESTAMP\\nJOB_NAME=spectrain_cnn_hpt_$TIMESTAMP\\n\\nPYTHON_PACKAGE_URI=gs://${BUCKET}/spectrain_cnn/spectrain_proc_img_trainer-0.1.tar.gz\\nPYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\\nPYTHON_MODULE=trainer.task\\n\\necho > ./hyperparam.yaml \"displayName: $JOB_NAME\\nstudySpec:\\n  metrics:\\n  - metricId: val_auc\\n    goal: MAXIMIZE\\n  parameters:\\n  - parameterId: batch_size\\n    integerValueSpec:\\n      minValue: 8\\n      maxValue: 64\\n    scaleType: UNIT_LOG_SCALE\\n  - parameterId: filt_size1\\n    integerValueSpec:\\n      minValue: 16\\n      maxValue: 64\\n    scaleType: UNIT_LINEAR_SCALE\\n  - parameterId: filt_size2\\n    integerValueSpec:\\n      minValue: 8\\n      maxValue: 32\\n    scaleType: UNIT_LINEAR_SCALE\\n  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\\ntrialJobSpec:\\n  baseOutputDirectory:\\n    outputUriPrefix: $BASE_OUTPUT_DIR\\n  workerPoolSpecs:\\n  - machineSpec:\\n      machineType: n1-standard-8\\n    pythonPackageSpec:\\n      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\\n      packageUris:\\n      - $PYTHON_PACKAGE_URI\\n      pythonModule: $PYTHON_MODULE\\n      args:\\n      - --train_data_path=gs://${BUCKET}/bhavani/train_images\\n      - --eval_data_path=gs://${BUCKET}/bhavani/valid_images\\n      - --num_epochs=10\\n      - --train_examples=5000\\n      - --eval_steps=100\\n      - --batch_size=32\\n    replicaCount: 1\"\\n        \\ngcloud ai hp-tuning-jobs create \\\\\\n    --region=$REGION \\\\\\n    --display-name=$JOB_NAME \\\\\\n    --config=hyperparam.yaml \\\\\\n    --max-trial-count=20 \\\\\\n    --parallel-trial-count=5\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_5113/2992613790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\\nBASE_OUTPUT_DIR=gs://${BUCKET}/spectrain_cnn/hp_tuning_$TIMESTAMP\\nJOB_NAME=spectrain_cnn_hpt_$TIMESTAMP\\n\\nPYTHON_PACKAGE_URI=gs://${BUCKET}/spectrain_cnn/spectrain_proc_img_trainer-0.1.tar.gz\\nPYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\\nPYTHON_MODULE=trainer.task\\n\\necho > ./hyperparam.yaml \"displayName: $JOB_NAME\\nstudySpec:\\n  metrics:\\n  - metricId: val_auc\\n    goal: MAXIMIZE\\n  parameters:\\n  - parameterId: batch_size\\n    integerValueSpec:\\n      minValue: 8\\n      maxValue: 64\\n    scaleType: UNIT_LOG_SCALE\\n  - parameterId: filt_size1\\n    integerValueSpec:\\n      minValue: 16\\n      maxValue: 64\\n    scaleType: UNIT_LINEAR_SCALE\\n  - parameterId: filt_size2\\n    integerValueSpec:\\n      minValue: 8\\n      maxValue: 32\\n    scaleType: UNIT_LINEAR_SCALE\\n  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\\ntrialJobSpec:\\n  baseOutputDirectory:\\n    outputUriPrefix: $BASE_OUTPUT_DIR\\n  workerPoolSpecs:\\n  - machineSpec:\\n      machineType: n1-standard-8\\n    pythonPackageSpec:\\n      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\\n      packageUris:\\n      - $PYTHON_PACKAGE_URI\\n      pythonModule: $PYTHON_MODULE\\n      args:\\n      - --train_data_path=gs://${BUCKET}/bhavani/train_images\\n      - --eval_data_path=gs://${BUCKET}/bhavani/valid_images\\n      - --num_epochs=10\\n      - --train_examples=5000\\n      - --eval_steps=100\\n      - --batch_size=32\\n    replicaCount: 1\"\\n        \\ngcloud ai hp-tuning-jobs create \\\\\\n    --region=$REGION \\\\\\n    --display-name=$JOB_NAME \\\\\\n    --config=hyperparam.yaml \\\\\\n    --max-trial-count=20 \\\\\\n    --parallel-trial-count=5\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\\nBASE_OUTPUT_DIR=gs://${BUCKET}/spectrain_cnn/hp_tuning_$TIMESTAMP\\nJOB_NAME=spectrain_cnn_hpt_$TIMESTAMP\\n\\nPYTHON_PACKAGE_URI=gs://${BUCKET}/spectrain_cnn/spectrain_proc_img_trainer-0.1.tar.gz\\nPYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\\nPYTHON_MODULE=trainer.task\\n\\necho > ./hyperparam.yaml \"displayName: $JOB_NAME\\nstudySpec:\\n  metrics:\\n  - metricId: val_auc\\n    goal: MAXIMIZE\\n  parameters:\\n  - parameterId: batch_size\\n    integerValueSpec:\\n      minValue: 8\\n      maxValue: 64\\n    scaleType: UNIT_LOG_SCALE\\n  - parameterId: filt_size1\\n    integerValueSpec:\\n      minValue: 16\\n      maxValue: 64\\n    scaleType: UNIT_LINEAR_SCALE\\n  - parameterId: filt_size2\\n    integerValueSpec:\\n      minValue: 8\\n      maxValue: 32\\n    scaleType: UNIT_LINEAR_SCALE\\n  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\\ntrialJobSpec:\\n  baseOutputDirectory:\\n    outputUriPrefix: $BASE_OUTPUT_DIR\\n  workerPoolSpecs:\\n  - machineSpec:\\n      machineType: n1-standard-8\\n    pythonPackageSpec:\\n      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\\n      packageUris:\\n      - $PYTHON_PACKAGE_URI\\n      pythonModule: $PYTHON_MODULE\\n      args:\\n      - --train_data_path=gs://${BUCKET}/bhavani/train_images\\n      - --eval_data_path=gs://${BUCKET}/bhavani/valid_images\\n      - --num_epochs=10\\n      - --train_examples=5000\\n      - --eval_steps=100\\n      - --batch_size=32\\n    replicaCount: 1\"\\n        \\ngcloud ai hp-tuning-jobs create \\\\\\n    --region=$REGION \\\\\\n    --display-name=$JOB_NAME \\\\\\n    --config=hyperparam.yaml \\\\\\n    --max-trial-count=20 \\\\\\n    --parallel-trial-count=5\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/spectrain_cnn/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=spectrain_cnn_hpt_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/spectrain_cnn/spectrain_proc_img_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_auc\n",
    "    goal: MAXIMIZE\n",
    "  parameters:\n",
    "  - parameterId: batch_size\n",
    "    integerValueSpec:\n",
    "      minValue: 8\n",
    "      maxValue: 64\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: filt_size1\n",
    "    integerValueSpec:\n",
    "      minValue: 16\n",
    "      maxValue: 64\n",
    "    scaleType: UNIT_LINEAR_SCALE\n",
    "  - parameterId: filt_size2\n",
    "    integerValueSpec:\n",
    "      minValue: 8\n",
    "      maxValue: 32\n",
    "    scaleType: UNIT_LINEAR_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "      - --train_data_path=gs://${BUCKET}/bhavani/train_images\n",
    "      - --eval_data_path=gs://${BUCKET}/bhavani/valid_images\n",
    "      - --num_epochs=10\n",
    "      - --train_examples=5000\n",
    "      - --eval_steps=100\n",
    "      - --batch_size=32\n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91c051-4150-4dfe-b012-a8f051210c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the best hyperparameters after fine-tuning and train the final model\n",
    "%%bash\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "OUTDIR=gs://${BUCKET}/babyweight/tuned_$TIMESTAMP\n",
    "JOB_NAME=babyweight_tuned_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/babyweight/babyweight_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./tuned_config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-standard-8\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/babyweight/data/train*.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/babyweight/data/eval*.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=10\n",
    "    - --train_examples=20000\n",
    "    - --eval_steps=100\n",
    "    - --batch_size=32\n",
    "    - --nembeds=8\"\n",
    "    \n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=tuned_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bbb2c-5820-47df-988f-c7d060cd16bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4305d-24c1-471d-8ca0-61f433bd7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=local_training\n",
    "rm -rf ${OUTDIR}\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/spectrain_image_model\n",
    "python3 -m trainer.task \\\n",
    "    --train_data_path=gs://${BUCKET}/spectrain_image_model/train*.csv \\\n",
    "    --eval_data_path=gs://${BUCKET}/spectrain_image_model/eval*.csv \\\n",
    "    --output_dir=${OUTDIR} \\\n",
    "    --batch_size=32 \\\n",
    "    --num_epochs=1 \\\n",
    "    --train_examples=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e9353-ef8e-40bc-af06-461c7d3a6e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
